---
redirect_from: /_posts/2024-05-10-VQGraph.md
title: VQgraph
tags:
  - 论文阅读
---



# VQGRAPH: RETHINKING GRAPH REPRESENTATION SPACE FOR BRIDGING GNNS AND MLPS





## 1. Motivation

* 现有的GNNs都是基于消息传递（message passing）的，其推理速度会随着图规模呈指数级增长，对于现实场景中的应用是不合适的
* 目前主流的加速手段是 GNN-MLP 知识蒸馏，先使用 GNN 进行训练得到一个 teacher model，再蒸馏得到一个 MLP（student model）
  * SOTA 方法仅基于类别预测进行知识蒸馏 (class-based），类别数量有限，且 student model 没有学习到任何的结构知识
* 提出了基于 VQ-VAE 的变体 VQGraph
  * 同时利用结构知识和类别信息进行知识蒸馏



## 2. Method

* **Pipeline**

  ![](D:\DESKTOP\ML\papers\VQGraph\figures\pipeline.png)



* **Graph Tokenizer Training**

  * reconstruction loss

    ![](https://raw.githubusercontent.com/liyle3/picgo-resources/main/202503051925792.png)

  * codebook loss

    > only applies to the codebook variables, brings the selected code e close to the output of the encoder

    $$
    \mathcal{L}_{Code} = \frac{1}{N} \sum_{i=1}^{N}||sg[h_i] - e_{z_i}||^2 _2 \\
    z_i = argmin_{j}{||h_i - e_j||}
    $$

    

  * commitment loss

    > only applies to the encoder weights, encourages the output of the encoder to stay close to the chosen code to prevent it from fluctuating too frequently from one code vector to another

    $$
    \mathcal{L}_{Com} = \frac{\eta}{N} \sum_{i=1}^{N}||sg[e_{z_i}] - h_i||^2 _2
    $$

    

  * classification loss：cross entropy
    $$
    \mathcal{L}_{Cls} = \mathcal{L}_{CE}(y_{\{v_i\}}, \hat y_{\{e_{z_i}\}})
    $$
    
    
    

* **Distillation**
  $$
  \mathcal{L}_\rm{VQGRAPH} = \mathcal{L}_{cls} + \alpha \mathcal{L}_{class\_distill} + \beta \mathcal{L}_{code\_distill} 
  $$
  

  * Soft code assignment
    $$
    r_i^\rm{GNN} = \rm{COMP}(h_i ^{GNN}) \\
    r_i^\rm{MLP} = \rm{COMP}(h_i ^{MLP}) 
    $$

  * code distill loss

    ![](https://raw.githubusercontent.com/liyle3/picgo-resources/main/202503051925883.png)

    ![](https://raw.githubusercontent.com/liyle3/picgo-resources/main/202503051926123.png)